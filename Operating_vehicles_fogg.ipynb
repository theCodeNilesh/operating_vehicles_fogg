{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theCodeNilesh/operating_vehicles_fogg/blob/main/Operating_vehicles_fogg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4SBtj2jCTXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23075d0f-601f-410e-ccac-e68a1901a470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "PPOIq99RUXW4",
        "outputId": "c3c98a52-b86c-4601-c14c-5787c60b5d1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function recordVideo() {\n",
              "        const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
              "        const div = document.createElement('div');\n",
              "        const capture = document.createElement('button');\n",
              "        const stopCapture = document.createElement(\"button\");\n",
              "        capture.textContent = \"Start Recording\";\n",
              "        capture.style.background = \"green\";\n",
              "        capture.style.color = \"white\";\n",
              "        stopCapture.textContent = \"Stop Recording\";\n",
              "        stopCapture.style.background = \"red\";\n",
              "        stopCapture.style.color = \"white\";\n",
              "        div.appendChild(capture);\n",
              "        const video = document.createElement('video');\n",
              "        const recordingVid = document.createElement(\"video\");\n",
              "        video.style.display = 'block';\n",
              "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
              "        let recorder = new MediaRecorder(stream, options);\n",
              "        document.body.appendChild(div);\n",
              "        div.appendChild(video);\n",
              "        video.srcObject = stream;\n",
              "        await video.play();\n",
              "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "        await new Promise((resolve) => { capture.onclick = resolve; });\n",
              "        recorder.start();\n",
              "        capture.replaceWith(stopCapture);\n",
              "        await new Promise((resolve) => stopCapture.onclick = resolve);\n",
              "        recorder.stop();\n",
              "        let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
              "        let arrBuff = await recData.data.arrayBuffer();\n",
              "        stream.getVideoTracks()[0].stop();\n",
              "        div.remove();\n",
              "        let binaryString = \"\";\n",
              "        let bytes = new Uint8Array(arrBuff);\n",
              "        bytes.forEach((byte) => { binaryString += String.fromCharCode(byte); })\n",
              "        return btoa(binaryString);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished recording video. Saved binary under filename in current working directory: video.mp4\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def record_video(filename='video.mp4'):\n",
        "    js = Javascript(\"\"\"\n",
        "    async function recordVideo() {\n",
        "        const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "        const stopCapture = document.createElement(\"button\");\n",
        "        capture.textContent = \"Start Recording\";\n",
        "        capture.style.background = \"green\";\n",
        "        capture.style.color = \"white\";\n",
        "        stopCapture.textContent = \"Stop Recording\";\n",
        "        stopCapture.style.background = \"red\";\n",
        "        stopCapture.style.color = \"white\";\n",
        "        div.appendChild(capture);\n",
        "        const video = document.createElement('video');\n",
        "        const recordingVid = document.createElement(\"video\");\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n",
        "        let recorder = new MediaRecorder(stream, options);\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "        await new Promise((resolve) => { capture.onclick = resolve; });\n",
        "        recorder.start();\n",
        "        capture.replaceWith(stopCapture);\n",
        "        await new Promise((resolve) => stopCapture.onclick = resolve);\n",
        "        recorder.stop();\n",
        "        let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
        "        let arrBuff = await recData.data.arrayBuffer();\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "        let binaryString = \"\";\n",
        "        let bytes = new Uint8Array(arrBuff);\n",
        "        bytes.forEach((byte) => { binaryString += String.fromCharCode(byte); })\n",
        "        return btoa(binaryString);\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "    try:\n",
        "        display(js)\n",
        "        data = eval_js('recordVideo({})')\n",
        "        binary = b64decode(data)\n",
        "        with open(filename, \"wb\") as video_file:\n",
        "            video_file.write(binary)\n",
        "        print(f\"Finished recording video. Saved binary under filename in current working directory: {filename}\")\n",
        "    except Exception as err:\n",
        "        print(str(err))\n",
        "        return filename\n",
        "\n",
        "# Run the function, get the video path as saved in your notebook, and play it back here.\n",
        "video_path = record_video()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9bC-RAV7-ii",
        "outputId": "6c089594-53f2-4a33-cf19-ba3998a294ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rWG_EFS7-kU",
        "outputId": "aef992c1-5be1-49f9-8cfa-25c4ba4c9ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.11.4)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.2)\n",
            "Requirement already satisfied: ultralytics>=8.0.232 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.2.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (0.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7fVHSoQ7-p5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCSsbX0Z7-vC"
      },
      "outputs": [],
      "source": [
        "def DarkChannel(im, sz):\n",
        "    b, g, r = cv2.split(im)\n",
        "    dc = cv2.min(cv2.min(r, g), b)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (sz, sz))\n",
        "    dark = cv2.erode(dc, kernel)\n",
        "    return dark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq8IzdUc7-yq"
      },
      "outputs": [],
      "source": [
        "def AtmLight(img, dark):\n",
        "    A = np.percentile(img, 99.9, axis=(0, 1))  # Adjust percentile\n",
        "    return A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bjyf46-RC-55"
      },
      "outputs": [],
      "source": [
        "def TransmissionEstimate(im, A, sz):\n",
        "    omega = 0.92  # Adjust weight\n",
        "    im3 = np.empty(im.shape, im.dtype)\n",
        "\n",
        "    for ind in range(0, 3):\n",
        "        A_channel = A[ind]\n",
        "        im3[:, :, ind] = im[:, :, ind] / A_channel\n",
        "\n",
        "    transmission = 1 - omega * DarkChannel(im3, sz)\n",
        "    return transmission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFMvGYw7C-8W"
      },
      "outputs": [],
      "source": [
        "def Guidedfilter(I, p, r, eps):\n",
        "    mean_I = cv2.boxFilter(I, cv2.CV_64F, (r, r))\n",
        "    mean_p = cv2.boxFilter(p, cv2.CV_64F, (r, r))\n",
        "    mean_Ip = cv2.boxFilter(I * p, cv2.CV_64F, (r, r))\n",
        "    cov_Ip = mean_Ip - mean_I * mean_p\n",
        "\n",
        "    mean_II = cv2.boxFilter(I * I, cv2.CV_64F, (r, r))\n",
        "    var_I = mean_II - mean_I * mean_I\n",
        "\n",
        "    a = cov_Ip / (var_I + eps)\n",
        "    b = mean_p - a * mean_I\n",
        "\n",
        "    mean_a = cv2.boxFilter(a, cv2.CV_64F, (r, r))\n",
        "    mean_b = cv2.boxFilter(b, cv2.CV_64F, (r, r))\n",
        "\n",
        "    q = mean_a * I + mean_b\n",
        "    return q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jbem1gsC-_m"
      },
      "outputs": [],
      "source": [
        "def TransmissionRefine(im, et):\n",
        "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "    r = 50  # radius of filter\n",
        "    eps = 0.0001  # regularization parameter\n",
        "    t = Guidedfilter(gray, et, r, eps)\n",
        "    return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlypnWmDC_Bn"
      },
      "outputs": [],
      "source": [
        "def Recover(im, t, A, tx=0.1):\n",
        "    res = np.empty(im.shape, im.dtype)\n",
        "    t = cv2.max(t, tx)\n",
        "\n",
        "    for ind in range(0, 3):\n",
        "        res[:, :, ind] = (im[:, :, ind] - A[ind]) / t + A[ind]\n",
        "\n",
        "    return res.clip(0, 1)  #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl-hptRqC_Dq"
      },
      "outputs": [],
      "source": [
        "def enhance_quality(frame):\n",
        "    # Gamma correction\n",
        "    gamma = 1.05\n",
        "    enhanced_frame = np.clip(((frame * 255 / 255) ** gamma) * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return enhanced_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxy4jSV0C_Gv"
      },
      "outputs": [],
      "source": [
        "video_path = \"/content/video.mp4\"\n",
        "\n",
        "output_video_path = \"/content/Output_sample.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RmwNNMgC_Hu"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4vmZ1AFD5jo"
      },
      "outputs": [],
      "source": [
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGMfe7VhD5mk"
      },
      "outputs": [],
      "source": [
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYzj7XymD5o2"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    I = frame.astype('float64') / 255\n",
        "\n",
        "    dark = DarkChannel(I, 20)  # Adjusted window size\n",
        "    A = AtmLight(I, dark)\n",
        "    te = TransmissionEstimate(I, A, 20)  # Adjusted window size\n",
        "    t = TransmissionRefine(frame, te)\n",
        "    J = Recover(I, t, A, 0.05)  # Adjusted tx parameter for more haze removal\n",
        "\n",
        "    # Enhance quality and clarity\n",
        "    J = enhance_quality(J)\n",
        "\n",
        "    # Write the processed frame to the output video\n",
        "    out.write(J)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scj47xobwJPe"
      },
      "outputs": [],
      "source": [
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smyV8i6KD5sQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InzZfp6_C_NZ",
        "outputId": "354714cd-5584-4950-944a-240a9f5e4df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=/content/Output_sample.mp4, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-304-g22361691 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 203MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "WARNING ⚠️ NMS time limit 0.550s exceeded\n",
            "video 1/1 (1/132) /content/Output_sample.mp4: 480x640 1 person, 52.0ms\n",
            "video 1/1 (2/132) /content/Output_sample.mp4: 480x640 1 person, 9.5ms\n",
            "video 1/1 (3/132) /content/Output_sample.mp4: 480x640 1 person, 9.4ms\n",
            "video 1/1 (4/132) /content/Output_sample.mp4: 480x640 1 person, 10.2ms\n",
            "video 1/1 (5/132) /content/Output_sample.mp4: 480x640 1 person, 9.4ms\n",
            "video 1/1 (6/132) /content/Output_sample.mp4: 480x640 1 person, 9.4ms\n",
            "video 1/1 (7/132) /content/Output_sample.mp4: 480x640 1 person, 9.4ms\n",
            "video 1/1 (8/132) /content/Output_sample.mp4: 480x640 1 person, 9.5ms\n",
            "video 1/1 (9/132) /content/Output_sample.mp4: 480x640 1 person, 9.4ms\n",
            "video 1/1 (10/132) /content/Output_sample.mp4: 480x640 1 person, 9.4ms\n",
            "video 1/1 (11/132) /content/Output_sample.mp4: 480x640 1 person, 9.4ms\n",
            "video 1/1 (12/132) /content/Output_sample.mp4: 480x640 1 person, 9.4ms\n",
            "video 1/1 (13/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (14/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (15/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (16/132) /content/Output_sample.mp4: 480x640 (no detections), 10.5ms\n",
            "video 1/1 (17/132) /content/Output_sample.mp4: 480x640 2 persons, 7.4ms\n",
            "video 1/1 (18/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (19/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (20/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (21/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (22/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (23/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (24/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (25/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (26/132) /content/Output_sample.mp4: 480x640 2 persons, 6.3ms\n",
            "video 1/1 (27/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (28/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (29/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (30/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (31/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (32/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (33/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (34/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (35/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (36/132) /content/Output_sample.mp4: 480x640 1 person, 6.2ms\n",
            "video 1/1 (37/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (38/132) /content/Output_sample.mp4: 480x640 1 person, 6.2ms\n",
            "video 1/1 (39/132) /content/Output_sample.mp4: 480x640 1 person, 9.5ms\n",
            "video 1/1 (40/132) /content/Output_sample.mp4: 480x640 1 person, 7.5ms\n",
            "video 1/1 (41/132) /content/Output_sample.mp4: 480x640 1 person, 7.9ms\n",
            "video 1/1 (42/132) /content/Output_sample.mp4: 480x640 1 person, 6.1ms\n",
            "video 1/1 (43/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (44/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (45/132) /content/Output_sample.mp4: 480x640 1 person, 7.4ms\n",
            "video 1/1 (46/132) /content/Output_sample.mp4: 480x640 1 person, 1 dog, 5.9ms\n",
            "video 1/1 (47/132) /content/Output_sample.mp4: 480x640 1 person, 6.1ms\n",
            "video 1/1 (48/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (49/132) /content/Output_sample.mp4: 480x640 1 person, 6.1ms\n",
            "video 1/1 (50/132) /content/Output_sample.mp4: 480x640 1 person, 5.9ms\n",
            "video 1/1 (51/132) /content/Output_sample.mp4: 480x640 1 person, 5.9ms\n",
            "video 1/1 (52/132) /content/Output_sample.mp4: 480x640 1 person, 1 cell phone, 6.3ms\n",
            "video 1/1 (53/132) /content/Output_sample.mp4: 480x640 1 person, 5.9ms\n",
            "video 1/1 (54/132) /content/Output_sample.mp4: 480x640 1 person, 6.1ms\n",
            "video 1/1 (55/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (56/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (57/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (58/132) /content/Output_sample.mp4: 480x640 1 person, 6.5ms\n",
            "video 1/1 (59/132) /content/Output_sample.mp4: 480x640 1 person, 5.9ms\n",
            "video 1/1 (60/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (61/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (62/132) /content/Output_sample.mp4: 480x640 1 person, 5.5ms\n",
            "video 1/1 (63/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (64/132) /content/Output_sample.mp4: 480x640 (no detections), 6.4ms\n",
            "video 1/1 (65/132) /content/Output_sample.mp4: 480x640 1 dog, 6.2ms\n",
            "video 1/1 (66/132) /content/Output_sample.mp4: 480x640 1 person, 6.9ms\n",
            "video 1/1 (67/132) /content/Output_sample.mp4: 480x640 (no detections), 6.0ms\n",
            "video 1/1 (68/132) /content/Output_sample.mp4: 480x640 1 cat, 6.0ms\n",
            "video 1/1 (69/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (70/132) /content/Output_sample.mp4: 480x640 (no detections), 6.0ms\n",
            "video 1/1 (71/132) /content/Output_sample.mp4: 480x640 (no detections), 6.1ms\n",
            "video 1/1 (72/132) /content/Output_sample.mp4: 480x640 1 person, 5.9ms\n",
            "video 1/1 (73/132) /content/Output_sample.mp4: 480x640 (no detections), 5.8ms\n",
            "video 1/1 (74/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (75/132) /content/Output_sample.mp4: 480x640 1 person, 6.1ms\n",
            "video 1/1 (76/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (77/132) /content/Output_sample.mp4: 480x640 1 person, 5.9ms\n",
            "video 1/1 (78/132) /content/Output_sample.mp4: 480x640 1 person, 6.1ms\n",
            "video 1/1 (79/132) /content/Output_sample.mp4: 480x640 1 person, 6.2ms\n",
            "video 1/1 (80/132) /content/Output_sample.mp4: 480x640 1 person, 7.1ms\n",
            "video 1/1 (81/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (82/132) /content/Output_sample.mp4: 480x640 1 person, 6.1ms\n",
            "video 1/1 (83/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (84/132) /content/Output_sample.mp4: 480x640 (no detections), 6.3ms\n",
            "video 1/1 (85/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (86/132) /content/Output_sample.mp4: 480x640 1 person, 6.2ms\n",
            "video 1/1 (87/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (88/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (89/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (90/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (91/132) /content/Output_sample.mp4: 480x640 (no detections), 5.7ms\n",
            "video 1/1 (92/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (93/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (94/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (95/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (96/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (97/132) /content/Output_sample.mp4: 480x640 1 cat, 5.8ms\n",
            "video 1/1 (98/132) /content/Output_sample.mp4: 480x640 (no detections), 5.7ms\n",
            "video 1/1 (99/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (100/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (101/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (102/132) /content/Output_sample.mp4: 480x640 1 cat, 9.4ms\n",
            "video 1/1 (103/132) /content/Output_sample.mp4: 480x640 1 cat, 6.0ms\n",
            "video 1/1 (104/132) /content/Output_sample.mp4: 480x640 1 person, 5.9ms\n",
            "video 1/1 (105/132) /content/Output_sample.mp4: 480x640 1 person, 7.1ms\n",
            "video 1/1 (106/132) /content/Output_sample.mp4: 480x640 1 person, 5.9ms\n",
            "video 1/1 (107/132) /content/Output_sample.mp4: 480x640 1 person, 6.0ms\n",
            "video 1/1 (108/132) /content/Output_sample.mp4: 480x640 1 person, 6.1ms\n",
            "video 1/1 (109/132) /content/Output_sample.mp4: 480x640 1 cat, 6.5ms\n",
            "video 1/1 (110/132) /content/Output_sample.mp4: 480x640 1 person, 6.3ms\n",
            "video 1/1 (111/132) /content/Output_sample.mp4: 480x640 2 persons, 5.8ms\n",
            "video 1/1 (112/132) /content/Output_sample.mp4: 480x640 1 cat, 5.7ms\n",
            "video 1/1 (113/132) /content/Output_sample.mp4: 480x640 (no detections), 8.7ms\n",
            "video 1/1 (114/132) /content/Output_sample.mp4: 480x640 1 person, 11.2ms\n",
            "video 1/1 (115/132) /content/Output_sample.mp4: 480x640 (no detections), 5.6ms\n",
            "video 1/1 (116/132) /content/Output_sample.mp4: 480x640 1 person, 5.6ms\n",
            "video 1/1 (117/132) /content/Output_sample.mp4: 480x640 1 person, 6.5ms\n",
            "video 1/1 (118/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (119/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (120/132) /content/Output_sample.mp4: 480x640 1 person, 5.7ms\n",
            "video 1/1 (121/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (122/132) /content/Output_sample.mp4: 480x640 1 person, 5.6ms\n",
            "video 1/1 (123/132) /content/Output_sample.mp4: 480x640 1 person, 5.6ms\n",
            "video 1/1 (124/132) /content/Output_sample.mp4: 480x640 1 person, 6.4ms\n",
            "video 1/1 (125/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (126/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (127/132) /content/Output_sample.mp4: 480x640 1 person, 5.6ms\n",
            "video 1/1 (128/132) /content/Output_sample.mp4: 480x640 1 person, 5.6ms\n",
            "video 1/1 (129/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (130/132) /content/Output_sample.mp4: 480x640 1 person, 5.8ms\n",
            "video 1/1 (131/132) /content/Output_sample.mp4: 480x640 1 dog, 5.7ms\n",
            "video 1/1 (132/132) /content/Output_sample.mp4: 480x640 1 dog, 6.1ms\n",
            "Speed: 0.5ms pre-process, 6.9ms inference, 6.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python detect.py --source /content/Output_sample.mp4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "R4qN92AKKyNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70b1bf0-a352-4e10-b8a1-7422e8b5ada6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}